# üß© Carpeta `scripts/`

Scripts principales del proyecto: **preprocesamiento**, **preparaci√≥n de datos**, **entrenamiento** y **predicci√≥n**.  
Esta gu√≠a explica **qu√© hace cada script** y **c√≥mo usarlo**.

---

## üìë Tabla de contenidos
- [Requisitos y dependencias](#-requisitos-y-dependencias)
- [Flujo de trabajo (overview)](#-flujo-de-trabajo-overview)
- [1) `bag2mp4.py` ‚Äî Conversi√≥n y filtrado de .bag](#1-bag2mp4py--conversi√≥n-y-filtrado-de-bag)
- [2) `MpPose.py` ‚Äî Uso de Mediapipe Pose para extraer puntos del cuerpo](#2-mpposepy--uso-de-mediapipe-pose-para-extraer-puntos-del-cuerpo)
- [3) `Analizador.py` ‚Äî Manipulador de imagenes y videos](#3-analizadorpy--manipulador-de-imagenes-y-videos)
- [4) `Preparar_dataset.py` ‚Äî Construcci√≥n del dataset](#4-preparar_datasetpy--construcci√≥n-del-dataset)
- [5) `Entrenamiento.py` ‚Äî Modelo y entrenamiento](#5-entrenamientopy--modelo-y-entrenamiento)
- [6) `Tester.py` ‚Äî Predicci√≥n en video/imagen](#6-tester.py--predicci√≥n-en-videoimagen)
- [Convenciones de nombres y rutas](#-convenciones-de-nombres-y-rutas)
- [FAQ (errores comunes)](#-faq-errores-comunes)

---

## üî© Requisitos y dependencias

- Python 3.10+
- TensorFlow ‚â• 2.15
- MediaPipe ‚â• 0.10
- OpenCV (`opencv-python`)
- NumPy, Pandas, scikit-learn
- **Intel RealSense SDK** (`pyrealsense2`) para `bag2mp4.py` (Ubuntu)
---
## üß≠ Flujo de trabajo (overview)
``` bash
(Grabaci√≥n .bag)  ‚Üí  bag2mp4.py  ‚Üí  data/processed_videos/*.mp4
                              ‚Üì
                       Preparar_dataset.py  ‚Üí  data/csv/train_val_csv/*.csv, data/csv/test_csv/*.csv
                              ‚Üì
                        Entrenamiento.py  ‚Üí  models/best_model_XX.keras, models/mapeo_etiquetas.json
                              ‚Üì
                            Tester.py  ‚Üí  resultados/*.csv
```
---
## 1) bag2mp4.py ‚Äî Conversi√≥n y filtrado de .bag
**Prop√≥sito:** convertir grabaciones de Intel RealSense (.bag) a .mp4 aplicando filtro por rango de profundidad para eliminar fondo y dejar solo al sujeto.
### üß† Qu√© hace
- Lee frames RGB + Depth de .bag.
- Enmascara pixeles fuera de [min, max].
- Exporta .mp4 limpio (sin fondo).
### ‚ñ∂Ô∏è Uso (CLI)
- Par√°metros clave:
  - --video.bag
  - --distancia m√≠nima para el recorte (metros)
  - --distancia m√°xima para el recorte (metros)
**Uso rapido**
```bash
python bag2mp4.py video.bag \
                  --min 0.5 \
                  --max 1.0 \
```
**Nombre y ruta personalizada del video mp4 resultante**

```bash
python bag2mp4.py video.bag \
                  ruta/del/video_sin_fondo.mp4 \
                  --min 0.5 \
                  --max 1.0 \
```

La salida muestra la ruta del video sin fondo creado en formato mp4, el cual, por defecto tiene el mismo nombre que el archivo.bag procesado.

---

## 2) [MpPose.py](./MpPose.py) ‚Äî Uso de Mediapipe Pose para extraer puntos del cuerpo

**Prop√≥sito:** Detectar puntos del cuerpo y extraer coordenadas 3D con MediaPipe Pose.
### üß† Qu√© hace
Implementa una clase auxiliar que envuelve la funcionalidad de MediaPipe Pose para trabajar de forma sencilla con detecci√≥n de poses tanto en im√°genes est√°ticas como en videos.

Sus principales funciones son:
  - Inicializar el modelo de MediaPipe Pose en modo imagen est√°tica o en modo video, con model_complexity=2 para mayor precisi√≥n.
  - Procesar frames (`process()`) y, opcionalmente, dibujar la silueta y conexiones de los 33 puntos clave del cuerpo humano.
  - Contar puntos visibles (`cuenta_puntos()`) filtrando por un umbral m√≠nimo de visibilidad, √∫til para descartar frames incompletos o con detecci√≥n deficiente.
  - Extraer valores (x, y, z) (`extrae_valores()`) de cada punto detectado, devolviendo un vector de 99 caracter√≠sticas, y a√±adir etiqueta (label) si est√° en modo entrenamiento.
  - Generar nombres de columnas (`create_lists()`) para los datasets CSV, combinando el nombre anat√≥mico del punto y sus coordenadas.
---
## 3) [Analizador.py](./Analizador.py) ‚Äî Manipulador de imagenes y videos
**Prop√≥sito:** Servir como herramienta para la etapa de predicci√≥n y generaci√≥n de datasets, permitiendo procesar videos e im√°genes mediante MediaPipe Pose. 

### üß† Qu√© hace
Implementa dos clases auxiliares (Video e Imagen) que utilizan la clase MpPose para procesar videos e im√°genes en la etapa de predicci√≥n y extracci√≥n de datos para entrenamiento.

Sus principales funciones son:
- Clase `Video`:
  - Inicializar (`__init__()`) ‚Üí carga un video desde la ruta indicada, configura si est√° en modo entrenamiento (train=True) y prepara un detector de poses MpPose.
  - Predecir poses en video (`Prediccion()`) ‚Üí procesa un video completo con un modelo entrenado:
    - Analiza cada cierto n√∫mero de frames (step) para optimizar tiempo de ejecuci√≥n.
    - Extrae coordenadas (x, y, z) con MpPose.
    - Predice la pose usando el modelo.
    - Guarda los resultados en un CSV con columnas: Segundo, Pose.
  - Extraer frames para dataset (`Extrae_frames()`) ‚Üí procesa un video etiquetado para obtener coordenadas (x, y, z) de cada uno de los 33 puntos del cuerpo:
    - Solo guarda frames donde se detectan los 33 puntos.
    - Genera un CSV con 99 columnas de coordenadas + 1 columna label.
  - Guardar CSV (`guardaCSV()`) ‚Üí exporta la lista de resultados (self.data) a un archivo CSV, asignando nombres de columnas dependiendo si es modo entrenamiento o predicci√≥n.
- `Clase Imagen`:
  - Inicializar (`__init__()`) ‚Üí carga una imagen desde la ruta indicada y prepara MpPose en modo imagen est√°tica.
  - Predecir pose en imagen (`Predice()`) ‚Üí procesa la imagen para:
    - Detectar los 33 puntos clave del cuerpo.
    - Predecir la pose con el modelo entrenado.
    - Mostrar en pantalla la imagen con el nombre de la pose detectada, si se solicita (muestra=True).
---
## 4) [Preparar_dataset.py](./Preparar_dataset.py) ‚Äî Construcci√≥n del dataset
**Prop√≥sito:** Automatizar la generaci√≥n de datasets a partir de videos .mp4 ya preprocesados (sin fondo): crea carpetas de salida, extrae coordenadas (x,y,z) de los 33 puntos (99 features) usando [Analizador.Video](#3-analizadorpy--manipulador-de-imagenes-y-videos), genera CSVs por video, y, al final, produce un CSV unificado por partici√≥n (train/val y test).
### üß† Qu√© hace
Recorre los videos procesados, extrae autom√°ticamente las coordenadas de todos los puntos detectados por MediaPipe Pose, guarda un CSV para cada video y finalmente combina los resultados en un √∫nico archivo por partici√≥n (entrenamiento/validaci√≥n y prueba). Est√° dise√±ado para estructurar los datos de forma uniforme y lista para ser utilizada en el entrenamiento del modelo.
- `__init__()` ‚Üí Inicializa rutas base (data/) y placeholders para data_test y data_train_val.
- `Crea_carpetas()` ‚Üí Crea (si no existen) las rutas:
  - [data/csv/train_val_csv/](../data/csv/train_val_csv).
  - [data/csv/test_csv/](../data/csv/test_csv).
- `Extrae_frames()`:
  - Busca todos los .mp4 dentro de data/processed_videos/, ignorando la subcarpeta llamada PruebasReales.
  - La etiqueta se toma del nombre del archivo (path.stem.upper()).
  - Decide la carpeta de salida en funci√≥n de la ubicaci√≥n del video:
    - Si la subcarpeta en la que se encuentra se llama train_val ‚Üí guarda en train_val_csv/
    - En cualquier otro caso ‚Üí guarda en test_csv/
  - Para cada video:
    - Instancia `Video(path, train=True)`.
    - Llama a `Video.Extrae_frames(label, ruta_salida, step=5, reproduce=False)` para generar el CSV.
    - Solo guarda frames con los 33 puntos detectados con un `paso` de 5 frames.
- `Une_csvs()` ‚Üí Para cada carpeta (train_val_csv/ y test_csv/):
  - Concatena todos los CSVs (excepto dataset_completo.csv cuando ya hay uno generado).
  - Elimina duplicados.
  - Guarda un CSV unificado llamado dataset_completo.csv en esa carpeta.
- `main()` ‚Üí Ejecuta la secuencia completa:
  - Crea_carpetas()
  - Extrae_frames()
  - Une_csvs().
### ‚ñ∂Ô∏è Uso (CLI)
El script puede ejecutarse directamente desde la terminal como paquete:
``` bash
python -m scripts.Preparar_dataset.py
```
### üîç Notas y consideraciones
- `step=5` en `Extrae_frames()` controla cada cu√°ntos frames se extraen features (puedes ajustarlo dentro del script si necesitas m√°s/menos densidad).
- Solo se guardan registros cuando MediaPipe detecta los 33 puntos (calidad ajustable).
- La etiqueta depende estrictamente del nombre de archivo; evita espacios raros y mant√©n una convenci√≥n clara.
- `Une_csvs()` elimina duplicados (√∫til si hay solapamientos).

### ‚ö†Ô∏è Errores comunes
- No genera CSVs ‚Üí Revisa que processed_videos/ tenga .mp4 fuera de PruebasReales/ y que la detecci√≥n de puntos funcione (iluminaci√≥n/encuadre).
- Todo cae en test_csv/ ‚Üí Aseg√∫rate de que los videos para entrenamiento est√©n bajo una carpeta padre llamada train_val.
- Clases inesperadas ‚Üí El nombre del video define la etiqueta. Renombra los archivos si es necesario.
---
## 5) [Entrenamiento.py](.Entrenamiento.py) ‚Äî Modelo y entrenamiento
**Prop√≥sito:** Entrenar y evaluar un clasificador multiclase a partir de las 99 caracter√≠sticas por frame, guardando el mejor modelo y registrando m√©tricas y gr√°ficas para an√°lisis de desempe√±o.
### üß† Qu√© hace
Este m√≥dulo carga los CSV unificados (`dataset_completo.csv`) de train/val y test, convierte las etiquetas a one-hot, construye una red neuronal densa (MLP) con BatchNormalization y Dropout, entrena con early saving del mejor modelo (por val_loss), eval√∫a en el conjunto de prueba y grafica la historia de entrenamiento (accuracy y loss).
- `__init__()` ‚Üí Inicializa dataframes de entrada, matrices X/Y para train/val/test, el modelo Keras y un LabelBinarizer para codificar etiquetas.
- `cargar_datos()` ‚Üí Lee:
  - data/csv/train_val_csv/dataset_completo.csv
  - data/csv/test_csv/dataset_completo.csv
- `dividir_datos()`:
  - Separa features y labels en train/val; hace one-hot con LabelBinarizer.
  - Realiza train_test_split estratificado (test_size=0.20, random_state=42).
  - Prepara X_test/Y_test desde el CSV de test y codifica sus etiquetas.
  - Guarda el mapeo √≠ndice ‚Üí clase en [models/mapeo_etiquetas.json](../models/mapeo_etiquetas.json).
- `construccion()`:
Crea un *Red Neuronal Densa*:
Input(n_features) ‚Üí Dense(128, relu) ‚Üí BatchNorm ‚Üí Dropout(0.30) ‚Üí
Dense(64, relu) ‚Üí BatchNorm ‚Üí Dropout(0.30) ‚Üí Dense(n_classes, softmax)
Compila con Adam(lr=1e-3), categorical_crossentropy, accuracy.
- `entrenamiento()`:
  - Autonumera models/best_model_*.keras seg√∫n los existentes.

Usa ModelCheckpoint(..., save_best_only=True, monitor='val_loss').

Entrena epochs=100, batch_size=256, validando con (X_val, Y_val).

Devuelve history (historial de m√©tricas).

evaluacion()

Imprime Accuracy en test.

Calcula confusion_matrix y classification_report (usando poses_lb.classes_).

graficar_entrenamiento(history)
Muestra dos gr√°ficas (accuracy y loss) con curvas de train y val.

getX_test_Y_test_poses_lb()
Devuelve (X_test, Y_test, poses_lb) para comparativas externas (√∫til en el notebook).

main()
Pipeline end-to-end: cargar_datos() ‚Üí dividir_datos() ‚Üí construccion() ‚Üí entrenamiento() ‚Üí evaluacion() ‚Üí graficar_entrenamiento().
