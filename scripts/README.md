# üß© Carpeta `scripts/`

Scripts principales del proyecto: **preprocesamiento**, **preparaci√≥n de datos**, **entrenamiento** y **predicci√≥n**.  
Esta gu√≠a explica **qu√© hace cada script** y **c√≥mo usarlo**.

---

## üìë Tabla de contenidos
- [Requisitos y dependencias](#-requisitos-y-dependencias)
- [Flujo de trabajo (overview)](#-flujo-de-trabajo-overview)
- [1) `bag2mp4.py` ‚Äî Conversi√≥n y filtrado de .bag](#1-bag2mp4py--conversi√≥n-y-filtrado-de-bag)
- [2) `MpPose.py` ‚Äî Uso de Mediapipe Pose para extraer puntos del cuerpo](#2-mpposepy--uso-de-mediapipe-pose-para-extraer-puntos-del-cuerpo)
- [3) `Analizador.py` ‚Äî Manipulador de imagenes y videos](#3-analizadorpy--manipulador-de-imagenes-y-videos)
- [4) `Preparar_dataset.py` ‚Äî Construcci√≥n del dataset](#4-preparar_dataset.py--construcci√≥n-del-dataset)
- [5) `Entrenamiento.py` ‚Äî Modelo y entrenamiento](#5-entrenamiento.py--modelo-y-entrenamiento)
- [6) `Tester.py` ‚Äî Predicci√≥n en video/imagen](#6-tester.py--predicci√≥n-en-videoimagen)
- [Convenciones de nombres y rutas](#-convenciones-de-nombres-y-rutas)
- [FAQ (errores comunes)](#-faq-errores-comunes)

---

## üî© Requisitos y dependencias

- Python 3.10+
- TensorFlow ‚â• 2.15
- MediaPipe ‚â• 0.10
- OpenCV (`opencv-python`)
- NumPy, Pandas, scikit-learn
- **Intel RealSense SDK** (`pyrealsense2`) para `bag2mp4.py` (Ubuntu)
---
## üß≠ Flujo de trabajo (overview)
``` bash
(Grabaci√≥n .bag)  ‚Üí  bag2mp4.py  ‚Üí  data/processed_videos/*.mp4
                              ‚Üì
                       Preparar_dataset.py  ‚Üí  data/csv/train_val_csv/*.csv, data/csv/test_csv/*.csv
                              ‚Üì
                        Entrenamiento.py  ‚Üí  models/best_model_XX.keras, models/mapeo_etiquetas.json
                              ‚Üì
                            Tester.py  ‚Üí  resultados/*.csv
```
---
## 1) bag2mp4.py ‚Äî Conversi√≥n y filtrado de .bag
Prop√≥sito: convertir grabaciones de Intel RealSense (.bag) a .mp4 aplicando filtro por rango de profundidad para eliminar fondo y dejar solo al sujeto.
### üß† Qu√© hace
- Lee frames RGB + Depth de .bag.
- Enmascara pixeles fuera de [min, max].
- Exporta .mp4 limpio (sin fondo).
### ‚ñ∂Ô∏è Uso (CLI)
- Par√°metros clave:
  - --video.bag
  - --distancia m√≠nima para el recorte (metros)
  - --distancia m√°xima para el recorte (metros)
**Uso rapido**
```bash
python bag2mp4.py video.bag \
                  --min 0.5 \
                  --max 1.0 \
```
**Nombre y ruta personalizada del video mp4 resultante**

```bash
python bag2mp4.py video.bag \
                  ruta/del/video_sin_fondo.mp4 \
                  --min 0.5 \
                  --max 1.0 \
```

La salida muestra la ruta del video sin fondo creado en formato mp4, el cual, por defecto tiene el mismo nombre que el archivo.bag procesado.

---

## 2) [MpPose.py](./MpPose.py) ‚Äî Uso de Mediapipe Pose para extraer puntos del cuerpo

**Prop√≥sito:** Detectar puntos del cuerpo y extraer coordenadas 3D con MediaPipe Pose.
### üß† Qu√© hace
Implementa una clase auxiliar que envuelve la funcionalidad de MediaPipe Pose para trabajar de forma sencilla con detecci√≥n de poses tanto en im√°genes est√°ticas como en videos.

Sus principales funciones son:
  - Inicializar el modelo de MediaPipe Pose en modo imagen est√°tica o en modo video, con model_complexity=2 para mayor precisi√≥n.
  - Procesar frames (`process()`) y, opcionalmente, dibujar la silueta y conexiones de los 33 puntos clave del cuerpo humano.
  - Contar puntos visibles (`cuenta_puntos()`) filtrando por un umbral m√≠nimo de visibilidad, √∫til para descartar frames incompletos o con detecci√≥n deficiente.
  - Extraer valores (x, y, z) (`extrae_valores()`) de cada punto detectado, devolviendo un vector de 99 caracter√≠sticas, y a√±adir etiqueta (label) si est√° en modo entrenamiento.
  - Generar nombres de columnas (`create_lists()`) para los datasets CSV, combinando el nombre anat√≥mico del punto y sus coordenadas.
---
## 3) [Analizador.py](./Analizador.py) ‚Äî Manipulador de imagenes y videos
**Prop√≥sito:** Servir como herramienta para la etapa de predicci√≥n y generaci√≥n de datasets, permitiendo procesar videos e im√°genes mediante MediaPipe Pose. 

### üß† Qu√© hace
Implementa dos clases auxiliares (Video e Imagen) que utilizan la clase MpPose para procesar videos e im√°genes en la etapa de predicci√≥n y extracci√≥n de datos para entrenamiento.

Sus principales funciones son:
- Clase `Video`:
  - Inicializar (`__init__()`) ‚Üí carga un video desde la ruta indicada, configura si est√° en modo entrenamiento (train=True) y prepara un detector de poses MpPose.
  - Predecir poses en video (`Prediccion()`) ‚Üí procesa un video completo con un modelo entrenado:
    - Analiza cada cierto n√∫mero de frames (step) para optimizar tiempo de ejecuci√≥n.
    - Extrae coordenadas (x, y, z) con MpPose.
    - Predice la pose usando el modelo.
    - Guarda los resultados en un CSV con columnas: Segundo, Pose.
  - Extraer frames para dataset (`Extrae_frames()`) ‚Üí procesa un video etiquetado para obtener coordenadas (x, y, z) de cada uno de los 33 puntos del cuerpo:
    - Solo guarda frames donde se detectan los 33 puntos.
    - Genera un CSV con 99 columnas de coordenadas + 1 columna label.
  - Guardar CSV (`guardaCSV()`) ‚Üí exporta la lista de resultados (self.data) a un archivo CSV, asignando nombres de columnas dependiendo si es modo entrenamiento o predicci√≥n.
